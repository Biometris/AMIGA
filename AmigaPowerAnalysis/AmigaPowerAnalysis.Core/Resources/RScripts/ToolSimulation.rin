# Load required packages and define additional source files with R functions
require(MASS)             # For negative binomial regression 
require(lsmeans)          # For forming predictions          
source = c("zBinomial.rin", "zPoisson.rin", "zMisc.rin")

# Retrieve parameters from call to R 
args = commandArgs(TRUE)
if (length(args) <= 1) {
  testDir = "Technical Documentation"
  testDir = "AllDistributions"
  testDir = "Simple"
  testNumber = 0

  headDir = "D:/Diverse Opdrachten/AMIGA Power analysis/TestData"
  settingsfile = file.path(headDir, testDir, paste(testNumber, "-Settings.csv", sep=""))
  datafile     = file.path(headDir, testDir, paste(testNumber, "-Input.csv", sep=""))
  outputfile   = file.path(headDir, testDir, paste(testNumber, "-Output.csv", sep=""))
  scriptsDirectory    = getwd()
} else {
  scriptsDirectory = args[1]
  settingsfile = args[2]
  datafile     = args[3]
  outputfile   = args[4]
  logfile      = args[5]
  sink(logfile)
}

# Load additional R scripts which should be in the same directory
for (i in 1:length(source)) {
  source(file.path(scriptsDirectory, source[[i]]))
}

# Read Settings; note that names of logical settings are appended in front with Is
settings = readSettings(settingsfile)
if ((settings$ExperimentalDesignType != "RandomizedCompleteBlocks") & (settings$ExperimentalDesignType != "CompletelyRandomized")) {
  stop("ExperimentalDesignType '", settings$ExperimentalDesignType, "' not yet implemented.", call. = FALSE)
}

# Initialize random generator
set.seed(settings$RandomNumberSeed)

# Additional settings
settings = c(settings, nGCI=100)          # Number of draws for Generalized Confidence Interval   
settings = c(settings, smallGCI=0.0001)   # Bound on back-transformed values for the LOG-transform
settings = c(settings, NumberOfEffects=3)
if (!is.na(settings$LocLower)) {settings$NumberOfEffects = settings$NumberOfEffects + settings$NumberOfEvaluationPoints }
if (!is.na(settings$LocUpper)) {settings$NumberOfEffects = settings$NumberOfEffects + settings$NumberOfEvaluationPoints }
settings = c(settings, TransformLocLower = NA, TransformLocUpper = NA)

# Read Design matrix created by C# with columns Constant, GMO, Dummy, Mod, Mean
data = read.csv(datafile, header=TRUE)
colnames = colnames(data)

# Redefine Mod columns to factors; Note that type of columns can be checked with sapply(data, class)
modifiers = grep("Mod", colnames)
nmodifiers = length(modifiers)
if (length(modifiers)>0) {
  for (i in 1:nmodifiers) {
    data[[modifiers[[i]]]] = as.factor(data[[modifiers[[i]]]])
  } 
}

# Create dataframe for prediction; only use GMO columns and Dummy columns
# This implies that the mean is taken over blocks and also over modifiers (if any)
predictors = grep("GMO", gsub("Dummy", "GMO", colnames))
preddata = head(data[predictors], 2)
preddata[,] = 0
preddata[1] = c(0,1)

# Create formulas for H0 and H1; Note that GMO is used to test the comparison
nterms = grep("Mean", colnames(data)) - 1
nameH1 = colnames[c(2:nterms)]
if (settings$ExperimentalDesignType == "RandomizedCompleteBlocks") { # Add blocking effect
  nameH1 = c(nameH1, "Block")
}
settings = c(settings, formulaH1     = as.formula(paste("Response ~ ", paste(nameH1, collapse="+"))))
settings = c(settings, formulaH0     = update(settings$formulaH1, ~ . - GMO))
settings = c(settings, formulaH0_low = update(settings$formulaH0, ~ . + offset(LowOffset)))
settings = c(settings, formulaH0_upp = update(settings$formulaH0, ~ . + offset(UppOffset)))

# Add several additional columns to the dataframe
data["TransformedMean"] = LinkFunction(data["Mean"], settings$MeasurementType)
data["Effect"]    = NaN
data["Response"]  = NaN
data["Block"]     = as.factor(1)
data["LowOffset"] = NaN
data["UppOffset"] = NaN

# Define structures to save results
nanalysis = length(settings$AnalysisMethods)
nrow = settings$NumberOfSimulatedDataSets
pvalues = list(
    Diff   = matrix(nrow=nrow, ncol=nanalysis, dimnames=list(NULL, settings$AnalysisMethods)),
    Equi = matrix(nrow=nrow, ncol=nanalysis, dimnames=list(NULL, settings$AnalysisMethods)),
    EquiWD = matrix(nrow=nrow, ncol=nanalysis, dimnames=list(NULL, settings$AnalysisMethods)))

nrow = length(settings$NumberOfReplications) * settings$NumberOfEffects
nrow
results = list(
    Effect = matrix(nrow=nrow, ncol=4, dimnames=list(NULL, c("Effect", "TransformedEffect", "CSD", "NumberOfReplications"))),
    Diff   = matrix(nrow=nrow, ncol=nanalysis, dimnames=list(NULL, paste("Diff",   settings$AnalysisMethods, sep=""))), 
    Equi   = matrix(nrow=nrow, ncol=nanalysis, dimnames=list(NULL, paste("Equi",   settings$AnalysisMethods, sep=""))), 
    EquiWD = matrix(nrow=nrow, ncol=nanalysis, dimnames=list(NULL, paste("EquiWD", settings$AnalysisMethods, sep=""))))

# Fill results$Effect
if (settings$MeasurementType != "Continuous") {
  settings$TransformLocLower = log(settings$LocLower)
  settings$TransformLocUpper = log(settings$LocUpper)
} else {
  settings$TransformLocLower = settings$LocLower - OverallMean
  settings$TransformLocUpper = settings$LocUpper + OverallMean
}
evaluationGrid = evaluationGrid(settings$TransformLocLower, settings$TransformLocUpper, settings$NumberOfEvaluationPoints)
effect = evaluationGrid$effect
neffect = length(effect)
nreplication = length(settings$NumberOfReplications)

results$Effect[,"TransformedEffect"]    = rep(effect, nreplication ) 
results$Effect[,"CSD"]                  = rep(evaluationGrid$csd, nreplication ) 
results$Effect[,"NumberOfReplications"] = rep(settings$NumberOfReplications, each=neffect)
if (settings$MeasurementType != "Continuous") {
  results$Effect[,"Effect"] = exp(results$Effect[,"TransformedEffect"])
} else {
  results$Effect[,"Effect"] = results$Effect[,"TransformedEffect"]
}
results$Effect

#########################################################################################################
# Relevant structures at this point are
#   settings: includes models to fit
#   data:     data passed by C# and appended with additional columns
#   preddata: to form predictions
#   pvalues:  to store intermediate results
#   results:  to save results    
#########################################################################################################


# Add blocking effect to model 
if (settings$ExperimentalDesignType == "RandomizedCompleteBlocks") {
  sigBlock = sqrt(log((settings$CVBlocks/100)*(settings$CVBlocks/100) + 1))
} else {
  sigBlock = 0
}

# Define dispersion parameter
dispersion = ropoissonDispersion(settings$OverallMean, settings$CVComparator, settings$PowerLawPower, settings$Distribution)
dispersion 

tel = 0
nloop = neffect*nreplication
ntimes = nloop*settings$NumberOfSimulatedDataSets
title = paste(settings$Endpoint, "  (Endpoint ", settings$ComparisonId+1, " of ", settings$NumberOfComparisons, ")", sep="")
progressbar <- winProgressBar(title=title, label="Number of replications", min=0, max=ntimes, width=400)
iprogressbar = 0
if (settings$NumberOfSimulatedDataSets < 10) {
  progressbarUpdate = 1
} else if (settings$NumberOfSimulatedDataSets < 50) {
  progressbarUpdate = 5
} else if (settings$NumberOfSimulatedDataSets < 100) {
  progressbarUpdate = 10
} else {
  progressbarUpdate = 10
}

for (i in 1:nreplication) {
  # Expand dataset and modify Block factor  
  iReps = settings$NumberOfReplications[i] 
  labeli = formatC(i, width=ceiling(log10(nreplication+0.5)), flag="0")
  labeli = sprintf("Number of replications: %s  (%s of %s)", iReps, labeli, nreplication)

  blocksi = iReps + 0*data[[1]]
  data.expanded = data[rep(row.names(data), blocksi), ]
  data.expanded[["Block"]] = as.factor(rep(1:iReps, nrow(data)))

  # Prepare for apply effect on the transformed scale
  applyeffect = (data.expanded["GMO"] == 1)
  data.expanded["Effect"] = data.expanded["TransformedMean"]

  # Apply blocking Effect on the transformed scale; use Blom scores
  if (settings$ExperimentalDesignType == "RandomizedCompleteBlocks") {
    blockeff = sigBlock*qnorm( ((1:iReps)-0.375)/(iReps+0.25) )
    data.expanded["Effect"] = data.expanded["Effect"] + blockeff[data.expanded[["Block"]]]
  }
  data.expanded["LowOffset"] = data.expanded["GMO"] * settings$TransformLocLower
  data.expanded["UppOffset"] = data.expanded["GMO"] * settings$TransformLocUpper
  nmean = length(data.expanded[["Effect"]])
  saveEffect = data.expanded[["Effect"]]

  for (j in 1:neffect) {
    labelj = formatC(j, width=ceiling(log10(neffect+0.5)), flag="0")
    labelj = sprintf("Effect %s (%s)", labelj, neffect)

    # Apply effect on the transformed scale and back-transform
    data.expanded[["Effect"]] = saveEffect
    data.expanded["Effect"][applyeffect] = effect[j] + data.expanded["Effect"][applyeffect]
    data.expanded["Effect"] = InverseLinkFunction(data.expanded["Effect"], settings$MeasurementType)

    # Do looping over simulations 
    for (k in 1:settings$NumberOfSimulatedDataSets) {
      # cat("    k=", k, "\n")
      simulated = ropoisson(nmean, data.expanded[["Effect"]], dispersion, settings$PowerLawPower, settings$Distribution)
      # ----------------------------------------------------------------------------------------------
      # LogNormal ------------------------------------------------------------------------------------
      # ----------------------------------------------------------------------------------------------
      if (!is.na(match("LogNormal", settings$AnalysisMethods))) {
        # cat("      settings$IsLogNormal", "\n")
        data.expanded["Response"] = log(simulated + 1)
        lmH1 = lm(settings$formulaH1, data=data.expanded)
        if (FALSE | (iprogressbar==0)) {
          cat("\nLogNormal\n=========\n")
          print(summary(lmH1))
        }
        pval = 2*pt(abs(lmH1$coef[2])/sqrt(vcov(lmH1)[2,2]), lmH1$df.residual, lower.tail=FALSE)
        pvalues$Diff[k, "LogNormal"] = pval
        resDF = df.residual(lmH1)
        resMS = deviance(lmH1)/resDF
        if (TRUE) {
          lsmeans = lsmeans(lmH1, "GMO", at=preddata)
          meanCMP = summary(lsmeans)$lsmean[1]
          meanGMO = summary(lsmeans)$lsmean[2]
          repCMP = resMS / (summary(lsmeans)$SE[1]^2)
          repGMO = resMS / (summary(lsmeans)$SE[2]^2)
          # Generalized confidence interval
          chi  = resDF * resMS / rchisq(settings$nGCI, resDF)
          rCMP = rnorm(settings$nGCI, meanCMP, sqrt(chi/repCMP))
          rGMO = rnorm(settings$nGCI, meanGMO, sqrt(chi/repGMO))
          rCMP = exp(rCMP + chi/2) - 1
          rGMO = exp(rGMO + chi/2) - 1
          rCMP[rCMP < settings$smallGCI] = settings$smallGCI
          rGMO[rGMO < settings$smallGCI] = settings$smallGCI
          ratio = rGMO/rCMP
          # print(data.frame(rchi, chi, rCMP, rGMO, ratio))
          # For very small drwas from the Chi-settings$Distribution rCMP and rGMO can be out of bounds
          quantiles = quantile(ratio, c(settings$SignificanceLevel/2, 1-settings$SignificanceLevel/2), na.rm=TRUE)
          if (iprogressbar==0) {
            cat("\n")
            cat("  meanCMP  : ", meanCMP, "\n")
            cat("  meanGMO  : ", meanGMO, "\n")
            cat("  repGMO   : ", repGMO,  "\n")
            cat("  repCMP   : ", repCMP,  "\n")
            cat("quantiles  : ", quantiles,  "\n")
            cat("\n")
          }
          if ((quantiles[1]>settings$LocLower) & (quantiles[2]<settings$LocUpper)) {
            pvalues$Equi[k, "LogNormal"] = 0
          } else {
            pvalues$Equi[k, "LogNormal"] = 1
          }
          pvalues$EquiWD[k, "LogNormal"] = NA
        }
      }

      # ----------------------------------------------------------------------------------------------
      # SquareRoot -----------------------------------------------------------------------------------
      # ----------------------------------------------------------------------------------------------
      if (!is.na(match("SquareRoot", settings$AnalysisMethods))) {
        data.expanded["Response"] = sqrt(simulated)
        lmH1 = lm(settings$formulaH1, data=data.expanded)
        if (FALSE | (iprogressbar==0)) {
          cat("\nSquareRoot\n==========\n")
          print(summary(lmH1))
        }
        pval = 2*pt(abs(lmH1$coef[2])/sqrt(vcov(lmH1)[2,2]), lmH1$df.residual, lower.tail=FALSE)
        pvalues$Diff[k, "SquareRoot"] = pval
        resDF = df.residual(lmH1)
        resMS = deviance(lmH1)/resDF
        if (TRUE) {
          lsmeans = lsmeans(lmH1, "GMO", at=preddata)
          meanCMP = summary(lsmeans)$lsmean[1]
          meanGMO = summary(lsmeans)$lsmean[2]
          repCMP = resMS / (summary(lsmeans)$SE[1]^2)
          repGMO = resMS / (summary(lsmeans)$SE[2]^2)

          # Generalized confidence interval
          chi  = resDF * resMS / rchisq(settings$nGCI, resDF)
          rCMP = rnorm(settings$nGCI, meanCMP, sqrt(chi/repCMP))
          rGMO = rnorm(settings$nGCI, meanGMO, sqrt(chi/repGMO))
          rCMP = rCMP*rCMP + chi
          rGMO = rGMO*rGMO + chi
          ratio = rGMO/rCMP
          quantiles = quantile(ratio, c(settings$SignificanceLevel/2, 1-settings$SignificanceLevel/2), na.rm=TRUE)
          if (iprogressbar==0) {
            cat("\n")
            cat("  meanCMP  : ", meanCMP, "\n")
            cat("  meanGMO  : ", meanGMO, "\n")
            cat("  repGMO   : ", repGMO,  "\n")
            cat("  repCMP   : ", repCMP,  "\n")
            cat("quantiles  : ", quantiles,  "\n")
            cat("\n")
          }
          if ((quantiles[1]>settings$LocLower) & (quantiles[2]<settings$LocUpper)) {
            pvalues$Equi[k, "SquareRoot"] = 0
          } else {
            pvalues$Equi[k, "SquareRoot"] = 1
          }
          pvalues$EquiWD[k, "SquareRoot"] = NA
        }
      }

      # ----------------------------------------------------------------------------------------------
      # OverdispersedPoisson -------------------------------------------------------------------------
      # ----------------------------------------------------------------------------------------------
      if (!is.na(match("OverdispersedPoisson", settings$AnalysisMethods))) {
        # cat("      settings$IsOverdispersedPoisson", "\n")
        data.expanded["Response"] = simulated
        glmH0 = glm(settings$formulaH0, family="quasipoisson", data=data.expanded, mustart=data.expanded[["Effect"]])
        glmH1 = glm(settings$formulaH1, family="quasipoisson", data=data.expanded, mustart=data.expanded[["Effect"]])
        if (FALSE | (iprogressbar==0)) {
          cat("\nOverdispersedPoisson\n====================\n")
          print(summary(glmH1))
        }

        # Difference test         esti = glmH1$coef[2]
        df1 = df.residual(glmH1)
        estDispersion = sum(residuals(glmH1,type="pearson")^2)/df1
        pval = pf((deviance(glmH0) - deviance(glmH1))/estDispersion, 1, df1, lower.tail=FALSE)
        pvalues$Diff[k, "OverdispersedPoisson"] = pval
        if (k == 1) {
          qt = abs(qt(settings$SignificanceLevel/2, df1, lower.tail=TRUE))
        }
        # Equivalence test 
        estiEffect = glmH1$coef[2]
        if ((estiEffect < settings$TransformLocLower) | (estiEffect > settings$TransformLocUpper)) {
          pvalues$EquiWD[k, "OverdispersedPoisson"] = 1
          pvalues$Equi[k, "OverdispersedPoisson"] = 1
        } else {
          # Wald equivalence test
          seEffect = sqrt(vcov(glmH1)[2,2])
          lower = estiEffect - qt * seEffect
          upper = estiEffect + qt * seEffect
          if ((lower > settings$TransformLocLower) & (upper < settings$TransformLocUpper)) {
            pvalues$EquiWD[k, "OverdispersedPoisson"] = 0
          } else {
            pvalues$EquiWD[k, "OverdispersedPoisson"] = 1
          }
          #stop("STOP")
          # LR equivalence test
          glmH0low = glm(settings$formulaH0_low, family="quasipoisson", data=data.expanded, mustart=fitted.values(glmH0))
          glmH0upp = glm(settings$formulaH0_upp, family="quasipoisson", data=data.expanded, mustart=fitted.values(glmH0))
          pvalLow = pf((deviance(glmH0low) - deviance(glmH1))/estDispersion, 1, df1, lower.tail=FALSE)
          pvalUpp = pf((deviance(glmH0upp) - deviance(glmH1))/estDispersion, 1, df1, lower.tail=FALSE)
          pvalues$Equi[k, "OverdispersedPoisson"] = max(pvalLow, pvalUpp)
        }
      }

      # ----------------------------------------------------------------------------------------------
      # NegativeBinomial -----------------------------------------------------------------------------
      # ----------------------------------------------------------------------------------------------
      if (!is.na(match("NegativeBinomial", settings$AnalysisMethods))) {
        # cat("      settings$IsNegativeBinomial", "\n")
        data.expanded["Response"] = simulated
        glmH0 = glm.nb(settings$formulaH0, data=data.expanded, link=log)
        glmH1 = glm.nb(settings$formulaH1, data=data.expanded, link=log, mustart=fitted.values(glmH0))
        if (FALSE | (iprogressbar==0)) {
          cat("\nNegativeBinomial\n================\n")
          print(summary(glmH1))
        }
        pval = pchisq(-2*(logLik(glmH0) - logLik(glmH1)), 1, lower.tail=FALSE)
        pvalues$Diff[k, "NegativeBinomial"] = pval

        estiEffect = glmH1$coef[2]
        if ((estiEffect < logLocLower) | (estiEffect > logLocUpper)) {
          pval = 1
        } else {
          glmH0low = glm.nb(settings$formulaH0_low, data=data.expanded, link=log, mustart=fitted.values(glmH0))
          glmH0upp = glm.nb(settings$formulaH0_upp, data=data.expanded, link=log, mustart=fitted.values(glmH0))
          pvalLow = pchisq(deviance(glmH0low) - deviance(glmH1), 1, lower.tail=FALSE)
          pvalUpp = pchisq(deviance(glmH0upp) - deviance(glmH1), 1, lower.tail=FALSE)
          pval = max(pvalLow, pvalUpp)
        } 
        pvalues$Equi[k, "NegativeBinomial"] = pval
      }
      iprogressbar = iprogressbar + 1
      if ((iprogressbar %% progressbarUpdate) == 0) {
        labelk = formatC(k, width=ceiling(log10(settings$NumberOfSimulatedDataSets+0.5)), flag="0")
        labelk = sprintf("Simulation %s (%s)", labelk, settings$NumberOfSimulatedDataSets)
        label = sprintf("%s;     %s;     %s", labeli, labelj, labelk)
        setWinProgressBar(progressbar, iprogressbar, label=label)
      }
    }
    tel = tel + 1
    results$Diff[tel,]   = colSums(pvalues$Diff   < settings$SignificanceLevel)/settings$NumberOfSimulatedDataSets
    results$Equi[tel,] = colSums(pvalues$Equi < settings$SignificanceLevel)/settings$NumberOfSimulatedDataSets
    results$EquiWD[tel,] = colSums(pvalues$EquiWD < settings$SignificanceLevel)/settings$NumberOfSimulatedDataSets
  }
}
close(progressbar)
warnings()
print(results$Effects)
print(results$Diff)
print(results$Equi)
print(results$EquiWD)

# Combine results into a single dataframe
df=cbind(results$Effect, results$Diff, results$Equi, results$EquiWD)

# Sort according to Ratio and NumberReplicates
#df = df[ order(df[,2], df[,2]), ]
df
write.table(df, file=outputfile, quote=FALSE, sep=",", row.names=FALSE, col.names=TRUE, na="*")
q()


